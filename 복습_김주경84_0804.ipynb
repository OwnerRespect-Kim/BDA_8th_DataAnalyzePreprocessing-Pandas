{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF (Term Frequency - Inverse Document Frequency)  \n",
    "- #### TF (Term Frequency)  \n",
    "    정의 : 특정 단어가 문서 내에서 얼마나 자주 등장하는지를 측정하는 것  \n",
    "    계산 방법 :  \n",
    "        TF(t, d) = (해당 단어 t의 빈도수) / (문서 d의 총 단어 수)  \n",
    "    목적 : 문서 내에서 단어의 중요성을 평가  \n",
    "          \n",
    "- #### IDF (Inverse Document Frequency)  \n",
    "    정의 : 특정 단어가 전체 문서에서 얼마나 흔하지 않은지를 측정하는 것  \n",
    "    계산 방법 :  \n",
    "        IDF(t) = log (전체 문서 수) / (단어 t가 포함된 문서 수)  \n",
    "    목적 : 흔한 단어의 가중치는 낮추고, 드문 단어의 가중치를 높임  \n",
    "  \n",
    "- #### TF-IDF  \n",
    "    정의 : TF와 IDF를 결합하여 각 단어의 중요도를 계산  \n",
    "    계산 방법 :  \n",
    "        TF-IDF(t, d) = TF(t, d) X IDF(t)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TfidfVectorizer  \n",
    "- TF-IDF 방식으로 텍스트 데이터를 벡터화하는데 사용된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF 패키지 불러오기\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예시 리스트\n",
    "lists = [\n",
    "    'This is the first lists',\n",
    "    'This lists is the second lists',\n",
    "    'And this lists is the third one',\n",
    "    'Is this the first lists?'\n",
    "]\n",
    "\n",
    "# TF-IDF 벡터라이저 초기화\n",
    "lists_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# 문서 데이터(위의 예시 리스트)를 TF-IDF 값으로 벡터화\n",
    "X = lists_vectorizer.fit_transform(lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lists 사용한 피처 확인 ['and' 'first' 'is' 'lists' 'one' 'second' 'the' 'third' 'this']\n",
      "----\n",
      "TF-IDF 매트릭스\n",
      " [[0.         0.60276058 0.39896105 0.39896105 0.         0.\n",
      "  0.39896105 0.         0.39896105]\n",
      " [0.         0.         0.30610726 0.61221452 0.         0.5865905\n",
      "  0.30610726 0.         0.30610726]\n",
      " [0.49451206 0.         0.25805691 0.25805691 0.49451206 0.\n",
      "  0.25805691 0.49451206 0.25805691]\n",
      " [0.         0.60276058 0.39896105 0.39896105 0.         0.\n",
      "  0.39896105 0.         0.39896105]]\n"
     ]
    }
   ],
   "source": [
    "# 변환 결과를 출력\n",
    "print('lists 사용한 피처 확인', lists_vectorizer.get_feature_names_out())\n",
    "print('----')\n",
    "print('TF-IDF 매트릭스\\n', X.toarray()) # 숫자의 의미는 단어의 빈도수를 의미한다.\n",
    "# TF-IDF의 값이 높다면 전체의 문서에서 자주 등장하는 것이 아닌 특정 문서에서 중요하게 등장하는 것을 의미한다.\n",
    "# TF-IDF의 값이 낮다면 전체의 문서에서 자주 등장하는 단어를 의미한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 한국어로 진행\n",
    "corpus_ko = [\n",
    "    '오늘 식사는 매우 맛있습니다',\n",
    "    '내일 식사는 매우 맛있을까요?',\n",
    "    '내일은 눈이 올 것 같습니다',\n",
    "    '모두 내일은 두꺼운옷을 준비하세요',\n",
    "    'BDA는 이제 곧 수료식을 진행합니다',\n",
    "    '우리는 꾸준히 운동합니다',\n",
    "    '우리는 내일도 내일또 운동합니다'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 추가하기!\n",
    "stop_words = ['bda는']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF 벡터라이저 초기화\n",
    "ko_vectorizer = TfidfVectorizer(stop_words=stop_words) # 제거할 불용어를 설정\n",
    "# 문서 데이터(위의 corpus_ko)를 TF-IDF 값으로 벡터화\n",
    "X = ko_vectorizer.fit_transform(corpus_ko)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용한 피처 확인 ['같습니다' '꾸준히' '내일' '내일도' '내일또' '내일은' '눈이' '두꺼운옷을' '맛있습니다' '맛있을까요' '매우'\n",
      " '모두' '수료식을' '식사는' '오늘' '우리는' '운동합니다' '이제' '준비하세요' '진행합니다']\n",
      "----\n",
      "TF-IDF 매트릭스\n",
      " [[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.54408243 0.         0.45163515 0.\n",
      "  0.         0.45163515 0.54408243 0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.54408243 0.         0.         0.\n",
      "  0.         0.         0.         0.54408243 0.45163515 0.\n",
      "  0.         0.45163515 0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.60981929 0.         0.         0.         0.         0.50620239\n",
      "  0.60981929 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.43218152\n",
      "  0.         0.52064676 0.         0.         0.         0.52064676\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.52064676 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.57735027 0.         0.         0.         0.         0.57735027\n",
      "  0.         0.57735027]\n",
      " [0.         0.64846464 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.53828134 0.53828134 0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.54408243 0.54408243 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.45163515 0.45163515 0.\n",
      "  0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# 변환 결과를 출력\n",
    "print('사용한 피처 확인', ko_vectorizer.get_feature_names_out())\n",
    "print('----')\n",
    "print('TF-IDF 매트릭스\\n', X.toarray()) # 숫자의 의미는 단어의 빈도수를 의미한다.\n",
    "# TF-IDF의 값이 높다면 전체의 문서에서 자주 등장하는 것이 아닌 특정 문서에서 중요하게 등장하는 것을 의미한다.\n",
    "# TF-IDF의 값이 낮다면 전체의 문서에서 자주 등장하는 단어를 의미한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터를 좀 더 추가해서 다양하게 전처리 작업을 수행할 수 있다.\n",
    "# min_df는 최소 빈도수를 의미한다.\n",
    "# ngram_range는 단어의 묶음을 의미한다.\n",
    "ko_vectorizer = TfidfVectorizer(stop_words=stop_words, min_df = 2, ngram_range = (1, 2))\n",
    "X = ko_vectorizer.fit_transform(corpus_ko)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용한 피처 확인 ['내일은' '매우' '식사는' '식사는 매우' '우리는' '운동합니다']\n",
      "----\n",
      "TF-IDF 매트릭스\n",
      " [[0.         0.57735027 0.57735027 0.57735027 0.         0.        ]\n",
      " [0.         0.57735027 0.57735027 0.57735027 0.         0.        ]\n",
      " [1.         0.         0.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.70710678 0.70710678]\n",
      " [0.         0.         0.         0.         0.70710678 0.70710678]]\n"
     ]
    }
   ],
   "source": [
    "# 변환 결과를 출력\n",
    "print('사용한 피처 확인', ko_vectorizer.get_feature_names_out())\n",
    "print('----')\n",
    "print('TF-IDF 매트릭스\\n', X.toarray()) # 숫자의 의미는 단어의 빈도수를 의미한다.\n",
    "# ngram_range = (1, 2)를 통해 '날씨는 매우'와 같은 묶음을 만들 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텍스트 전처리를 통해 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('movie_rv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp = df.iloc[:20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 리뷰 데이터를 어떻게 분석하면 될까?!\n",
    "import re\n",
    "from konlpy.tag import Okt ## 한국어 형태소 분석기를 불러오는 모듈\n",
    "\n",
    "# Okt 형태소 분석기 생성\n",
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 유사도 측정, LDA 토픽모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fs/789w_bnn3h1crkt1ffyqbv700000gn/T/ipykernel_38374/1750553694.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sp['document_cleand'] = df_sp['document'].apply(preprocess_text)\n"
     ]
    }
   ],
   "source": [
    "## 전처리 함수\n",
    "def preprocess_text(text):\n",
    "    # 문자열 확인하고, 아니면 빈 문자열 반환\n",
    "    if not isinstance(text, str):\n",
    "        return ''\n",
    "    # 특수문자 제거\n",
    "    re.sub('r[^ㄱ-ㅎㅏ-ㅣ가-힣\\s]', '', text)\n",
    "    # 형태소로 분석을 통해 추출 (명사만 추출)\n",
    "    nouns = okt.nouns(text)\n",
    "    return ' '.join(nouns)\n",
    "\n",
    "df_sp['document_cleand'] = df_sp['document'].apply(preprocess_text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>document_cleand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>더빙 진짜 목소리</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>흠 포스터 보고 초딩 영화 줄 오버 연기</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>무재 밓었 다그 래서 추천</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>교도소 이야기 구먼 재미 평점 조정</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>몬페 의 연기 영화 스파이더맨 커스틴 던스트</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>커스턴양은 어려서나 지금이나 얼굴이 똑같네.</td>\n",
       "      <td>스턴 서나 지금 얼굴</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>초반부는 좋았는데 끝으로 갈수록 이건 뭐 코미디도 아니고...끝부분은 너무 유치했다...</td>\n",
       "      <td>초반 끝 갈수록 이건 뭐 코미디 끝 부분 애 쉿 빵 오컬트 요소 결말 수 차라리 스...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>작가야 왜 사냐~!!!!</td>\n",
       "      <td>작가 왜</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>내가 본 한국영화 top10에 들어감!!</td>\n",
       "      <td>내 한국영</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>어릴때봣엇지만매우재밋엇다</td>\n",
       "      <td>때봣 매우 재 밋엇다</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                document  \\\n",
       "0                                    아 더빙.. 진짜 짜증나네요 목소리   \n",
       "1                      흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나   \n",
       "2                                      너무재밓었다그래서보는것을추천한다   \n",
       "3                          교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정   \n",
       "4      사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...   \n",
       "...                                                  ...   \n",
       "19995                           커스턴양은 어려서나 지금이나 얼굴이 똑같네.   \n",
       "19996  초반부는 좋았는데 끝으로 갈수록 이건 뭐 코미디도 아니고...끝부분은 너무 유치했다...   \n",
       "19997                                      작가야 왜 사냐~!!!!   \n",
       "19998                             내가 본 한국영화 top10에 들어감!!   \n",
       "19999                                      어릴때봣엇지만매우재밋엇다   \n",
       "\n",
       "                                         document_cleand  \n",
       "0                                              더빙 진짜 목소리  \n",
       "1                                 흠 포스터 보고 초딩 영화 줄 오버 연기  \n",
       "2                                         무재 밓었 다그 래서 추천  \n",
       "3                                    교도소 이야기 구먼 재미 평점 조정  \n",
       "4                               몬페 의 연기 영화 스파이더맨 커스틴 던스트  \n",
       "...                                                  ...  \n",
       "19995                                        스턴 서나 지금 얼굴  \n",
       "19996  초반 끝 갈수록 이건 뭐 코미디 끝 부분 애 쉿 빵 오컬트 요소 결말 수 차라리 스...  \n",
       "19997                                               작가 왜  \n",
       "19998                                              내 한국영  \n",
       "19999                                        때봣 매우 재 밋엇다  \n",
       "\n",
       "[20000 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 전처리된 데이터와 원본 데이터를 비교해보자.\n",
    "display(df_sp[['document', 'document_cleand']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer  \n",
    "- 텍스트데이터를 단어 빈도 수를 기준으로 벡터화하는 것  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "X_cv_count = cv.fit_transform(df_sp['document_cleand'])\n",
    "\n",
    "# TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "X_tfidf_count = tfidf.fit_transform(df_sp['document_cleand'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 코사인 유사도  \n",
    "- cosine_similarity로 유사도를 측정하자!  \n",
    "  \n",
    "  #### cosine_similarity  \n",
    "  정의 :  \n",
    "  - 두 벡터 간의 각도를 기반으로 유사성을 측정하는 메트릭스  \n",
    "  - 두 벡터가 이루는 각의 코사인을 계산하여 유사도를 판단  \n",
    "  - 값의 범위는 [-1, 1]이며, 1에 가까울수록 두 벡터는 매우 유사하고, 0이면 직교, -1은 완전히 반대의 방향을 의미한다.  \n",
    "  \n",
    "  수식 :  \n",
    "  cosine_similarity(A, B) = (A ∙ B) / ||A|| ||B||  \n",
    "  * A ∙ B : 두 벡터의 내적  \n",
    "  * ||A||와 ||B||는 각 벡터의 유클리드 노름(= Euclidean norm)  \n",
    "    * 유클리드 노름(= 유클리드 길이, Euclidean length)이란? \n",
    "      - 우리가 일반적으로 생각하는 직선 거리  \n",
    "        ex) 2차원 평면 위의 벡터 (3,4)의 경우, 그 직선 거리는 3^2 + 4^2의 제곱근인 5가 된다.  \n",
    "      \n",
    "      \n",
    "  해당 함수는 두 벡터의 배열을 입력 받아 코사인 유사도를 계산 후 행렬로 반환한다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cosine_similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim_count = cosine_similarity(X_cv_count)\n",
    "cos_sim_tfidf = cosine_similarity(X_tfidf_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Original Review 1 : 아 더빙.. 진짜 짜증나네요 목소리\n",
      "\n",
      " Top 5 similar reviews using countvectorizer:\n",
      "Similarity : 1.000, Reviews:아 더빙.. 진짜 짜증나네요 목소리\n",
      "Similarity : 0.674, Reviews:러시아 영화 진짜 재미없다. 내용전개 진짜 이상하고 이해안돼. 억지로 짜집기한거같아. 더빙도 왜 연예인인거야? 이수근 진짜 더빙 못한다. 한국측 더빙작가가 대본을 이상하게 짠거야, 뭐야? 진짜 이상하고 재미없었다. 아오 빡쳐 ㅡㅡ;;\n",
      "Similarity : 0.577, Reviews:진짜 재미없었다. 남는 것도 없고...\n",
      "Similarity : 0.577, Reviews:말이필요없다. 진짜너무재밌다.♥♥\n",
      "Similarity : 0.577, Reviews:진짜 좋았어요 ㅠㅠ\n",
      "\n",
      " Top 5 similar reviews using Tfidf:\n",
      "Similarity : 1.000, Reviews:아 더빙.. 진짜 짜증나네요 목소리\n",
      "Similarity : 0.637, Reviews:더빙이 똥이야 ....\n",
      "Similarity : 0.637, Reviews:엄청잼있겟당 (근대더빙이면좋겟는듯)\n",
      "Similarity : 0.637, Reviews:으아아 더빙을 어떻게한거냐\n",
      "Similarity : 0.555, Reviews:강소라씨의 목소리더빙은..그냥 성우가 하셨으면 진짜 짱이였을텐데...영화내용은 재밌고 교훈도 있고!!\n",
      "\n",
      " Original Review 2 : 흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\n",
      "\n",
      " Top 5 similar reviews using countvectorizer:\n",
      "Similarity : 1.000, Reviews:흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\n",
      "Similarity : 0.577, Reviews:포스터가 영화를 망쳤어 ㅠ\n",
      "Similarity : 0.577, Reviews:너무 보고 싶은 영화~~\n",
      "Similarity : 0.577, Reviews:초딩영화 라고 하는 놈들은 죄다 ㅄ 들이다.\n",
      "Similarity : 0.577, Reviews:넘 사랑스러운 영화다 ㅠㅠ 1보고 2 연이어 봤다~!! 넘 귀여워 ㅠㅠ♥♥\n",
      "\n",
      " Top 5 similar reviews using Tfidf:\n",
      "Similarity : 1.000, Reviews:흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\n",
      "Similarity : 0.518, Reviews:초딩영화 라고 하는 놈들은 죄다 ㅄ 들이다.\n",
      "Similarity : 0.500, Reviews:와 초딩때보고 다시 보니깐 재밌네\n",
      "Similarity : 0.492, Reviews:초딩이봐도 욕하겠다.\n",
      "Similarity : 0.484, Reviews:포스터랑 영화랑 너무 다르다 ㅠ 그래서 더 좋았음.\n",
      "\n",
      " Original Review 3 : 너무재밓었다그래서보는것을추천한다\n",
      "\n",
      " Top 5 similar reviews using countvectorizer:\n",
      "Similarity : 1.000, Reviews:너무재밓었다그래서보는것을추천한다\n",
      "Similarity : 0.632, Reviews:너무재밋다 추천하고싶다\n",
      "Similarity : 0.447, Reviews:추천추천!! 또 보고싶어요!\n",
      "Similarity : 0.447, Reviews:너무재밋다...눈을뗄수가없다...\n",
      "Similarity : 0.447, Reviews:너무재밋어요 ㅎㅎ..\n",
      "\n",
      " Top 5 similar reviews using Tfidf:\n",
      "Similarity : 1.000, Reviews:너무재밓었다그래서보는것을추천한다\n",
      "Similarity : 0.519, Reviews:너무재밋다 추천하고싶다\n",
      "Similarity : 0.424, Reviews:너무재밋다...눈을뗄수가없다...\n",
      "Similarity : 0.424, Reviews:너무재밋어요 ㅎㅎ..\n",
      "Similarity : 0.319, Reviews:진짜너무너무재밋고계속해서나왓으면ㅜㅜㅠ\n",
      "\n",
      " Original Review 4 : 교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정\n",
      "\n",
      " Top 5 similar reviews using countvectorizer:\n",
      "Similarity : 1.000, Reviews:교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정\n",
      "Similarity : 0.577, Reviews:평점조정 좋은데 왜그래?\n",
      "Similarity : 0.577, Reviews:재미잇어요~ 신비로운 이야기~ ㅎㅎ\n",
      "Similarity : 0.471, Reviews:이거 평점이 너무 낮네;;난 감동깊게 봤는데..재미도 있었고..\n",
      "Similarity : 0.471, Reviews:평점좋아 봤는데 완젼 재미 더럽게 없다.\n",
      "\n",
      " Top 5 similar reviews using Tfidf:\n",
      "Similarity : 1.000, Reviews:교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정\n",
      "Similarity : 0.537, Reviews:평점조정 좋은데 왜그래?\n",
      "Similarity : 0.452, Reviews:평점 조정을 위해...\n",
      "Similarity : 0.429, Reviews:ㅎㅎㅎ재밋구먼\n",
      "Similarity : 0.382, Reviews:재미잇어요~ 신비로운 이야기~ ㅎㅎ\n",
      "\n",
      " Original Review 5 : 사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다\n",
      "\n",
      " Top 5 similar reviews using countvectorizer:\n",
      "Similarity : 1.000, Reviews:사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다\n",
      "Similarity : 0.577, Reviews:엄청난 연기들이 이 영화를 여전히 따뜻하게 해준다\n",
      "Similarity : 0.548, Reviews:첨엔 뭐 연기가 이래 했는데 연기로보는 영화가 아님 ㅋㅋㅋ웃겨죽는줄!\n",
      "Similarity : 0.500, Reviews:어렸을때 본 영화인데 좀 감동적이고 연기도 좋았다.. 한 번쯤 보면 괜찮은 영화!!\n",
      "Similarity : 0.500, Reviews:좋은 연기, 좋은 영화입니다. 악역없는 영화가 좋아요.\n",
      "\n",
      " Top 5 similar reviews using Tfidf:\n",
      "Similarity : 1.000, Reviews:사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다\n",
      "Similarity : 0.428, Reviews:커스틴 때문에 좋겠다\n",
      "Similarity : 0.367, Reviews:스파이더맨을 가장 좋아하는 1人~ 스파이더맨 완전 사랑합니다. 영원했으면 좋겠네요!!\n",
      "Similarity : 0.344, Reviews:내가 영화보면서 처음 눈물 흘리고 본게 스파이더맨3다.나는 어메이징, 스파이더맨 다 좋다. 하지만 내가제일 감명 깊게 본건 스파이더맨 시리즈이면서스파이더맨3다. 할 말이 필요없다. 지금까지도계속 챙겨보고 있다. 이것만 100번은 넘게본거 같다\n",
      "Similarity : 0.293, Reviews:선과 악의 기로에 서는.스파이더맨...토비의 스파이더맨은 이런 인생에서 한번쯤 일어날 법한 일을 담고 있는 영화인 것 같음.\n",
      "\n",
      " Original Review 6 : 막 걸음마 뗀 3세부터 초등학교 1학년생인 8살용영화.ㅋㅋㅋ...별반개도 아까움.\n",
      "\n",
      " Top 5 similar reviews using countvectorizer:\n",
      "Similarity : 1.000, Reviews:막 걸음마 뗀 3세부터 초등학교 1학년생인 8살용영화.ㅋㅋㅋ...별반개도 아까움.\n",
      "Similarity : 0.577, Reviews:별 반개도 아까운 이상하고 무서운 영화(물론 안봄)\n",
      "Similarity : 0.577, Reviews:와 ㅋㅋ 별 반개는 꼭 줘야되네요 ㅋㅋㅋㅋ 아놔 화나는 영화 ㅋㅋ\n",
      "Similarity : 0.471, Reviews:별 반개도 아까움 .. 아나 진짜 이런영화 왜만드는거야??\n",
      "Similarity : 0.471, Reviews:별 반개도 아깝다 진짜 OOO기영화\n",
      "\n",
      " Top 5 similar reviews using Tfidf:\n",
      "Similarity : 1.000, Reviews:막 걸음마 뗀 3세부터 초등학교 1학년생인 8살용영화.ㅋㅋㅋ...별반개도 아까움.\n",
      "Similarity : 0.416, Reviews:초등학교 6학년 도서관에서 봤는데 아직도 잊을 수가 없다\n",
      "Similarity : 0.405, Reviews:초등학교 5학년때 우연히 테레비로 방영했는데 이거 끝나자마자 울었음....ㅠㅠ\n",
      "Similarity : 0.402, Reviews:별 반개도 아까운 이상하고 무서운 영화(물론 안봄)\n",
      "Similarity : 0.402, Reviews:와 ㅋㅋ 별 반개는 꼭 줘야되네요 ㅋㅋㅋㅋ 아놔 화나는 영화 ㅋㅋ\n",
      "\n",
      " Original Review 7 : 원작의 긴장감을 제대로 살려내지못했다.\n",
      "\n",
      " Top 5 similar reviews using countvectorizer:\n",
      "Similarity : 1.000, Reviews:원작의 긴장감을 제대로 살려내지못했다.\n",
      "Similarity : 0.577, Reviews:원작을 잘 못 살렸을 줄 알았는데 아니었다\n",
      "Similarity : 0.577, Reviews:제대로 저질\n",
      "Similarity : 0.577, Reviews:원작 망쳤네요\n",
      "Similarity : 0.577, Reviews:원작을 파.괴.한.다\n",
      "\n",
      " Top 5 similar reviews using Tfidf:\n",
      "Similarity : 1.000, Reviews:원작의 긴장감을 제대로 살려내지못했다.\n",
      "Similarity : 0.623, Reviews:감독이 원작을 제대로 읽어보기나 한건지..\n",
      "Similarity : 0.595, Reviews:제대로 저질\n",
      "Similarity : 0.580, Reviews:시시하다. 강한 긴장감이 없다.\n",
      "Similarity : 0.560, Reviews:오랜만에 본 제대로 귀여운영화 ㅋㅋ\n",
      "\n",
      " Original Review 8 : 별 반개도 아깝다 욕나온다 이응경 길용우 연기생활이몇년인지..정말 발로해도 그것보단 낫겟다 납치.감금만반복반복..이드라마는 가족도없다 연기못하는사람만모엿네\n",
      "\n",
      " Top 5 similar reviews using countvectorizer:\n",
      "Similarity : 1.000, Reviews:별 반개도 아깝다 욕나온다 이응경 길용우 연기생활이몇년인지..정말 발로해도 그것보단 낫겟다 납치.감금만반복반복..이드라마는 가족도없다 연기못하는사람만모엿네\n",
      "Similarity : 0.485, Reviews:너무 재미있어서 두번이나 반복해서 봤네...\n",
      "Similarity : 0.343, Reviews:정말 재미있는 드라마^^\n",
      "Similarity : 0.343, Reviews:사람마다 느끼는게 다르겠지만 전 정말 재밌게 봤습니다.\n",
      "Similarity : 0.343, Reviews:정말.. 아름다운 드라마 ㅠㅠ\n",
      "\n",
      " Top 5 similar reviews using Tfidf:\n",
      "Similarity : 1.000, Reviews:별 반개도 아깝다 욕나온다 이응경 길용우 연기생활이몇년인지..정말 발로해도 그것보단 낫겟다 납치.감금만반복반복..이드라마는 가족도없다 연기못하는사람만모엿네\n",
      "Similarity : 0.499, Reviews:너무 재미있어서 두번이나 반복해서 봤네...\n",
      "Similarity : 0.293, Reviews:저에게는 가장 인상 깊은 한국 영화임특히 반복해서 봐도 훌륭함\n",
      "Similarity : 0.292, Reviews:반전도없구 계속 같은내용만 반복되구 재미가없어지려하네여 ㅠ\n",
      "Similarity : 0.268, Reviews:달콤하지 않은 거짓말의 무한반복.\n",
      "\n",
      " Original Review 9 : 액션이 없는데도 재미 있는 몇안되는 영화\n",
      "\n",
      " Top 5 similar reviews using countvectorizer:\n",
      "Similarity : 1.000, Reviews:액션이 없는데도 재미 있는 몇안되는 영화\n",
      "Similarity : 0.816, Reviews:이 영화가 그렇게 재미 없었습니까?\n",
      "Similarity : 0.816, Reviews:왜 이런 영화들은 재미가 없는 걸까요??\n",
      "Similarity : 0.816, Reviews:난 이거 재미만 있던대 -_-; 그렇게까지 깔영화도 아니더만....;\n",
      "Similarity : 0.707, Reviews:진짜 나쁜영화..재미가 없어서 더 나쁜영화...\n",
      "\n",
      " Top 5 similar reviews using Tfidf:\n",
      "Similarity : 1.000, Reviews:액션이 없는데도 재미 있는 몇안되는 영화\n",
      "Similarity : 0.709, Reviews:와 재밌다 ㅋ 액션지림 ㄷ\n",
      "Similarity : 0.709, Reviews:액션신 없지만 재미있다.\n",
      "Similarity : 0.709, Reviews:액션 쩌네...\n",
      "Similarity : 0.709, Reviews:액션은 볼만\n",
      "\n",
      " Original Review 10 : 왜케 평점이 낮은건데? 꽤 볼만한데.. 헐리우드식 화려함에만 너무 길들여져 있나?\n",
      "\n",
      " Top 5 similar reviews using countvectorizer:\n",
      "Similarity : 1.000, Reviews:왜케 평점이 낮은건데? 꽤 볼만한데.. 헐리우드식 화려함에만 너무 길들여져 있나?\n",
      "Similarity : 0.816, Reviews:평점 왜케 낮어\n",
      "Similarity : 0.667, Reviews:평점이 왜케 낮지???? 이영화쩔었는데\n",
      "Similarity : 0.667, Reviews:왜케 평점이 낮지? 잼게 봣는뎅\n",
      "Similarity : 0.577, Reviews:평점이 6점이 넘다니!!! 말도 안돼!!!\n",
      "\n",
      " Top 5 similar reviews using Tfidf:\n",
      "Similarity : 1.000, Reviews:왜케 평점이 낮은건데? 꽤 볼만한데.. 헐리우드식 화려함에만 너무 길들여져 있나?\n",
      "Similarity : 0.752, Reviews:평점 왜케 낮어\n",
      "Similarity : 0.659, Reviews:헐리우드 너무 베꼈어..\n",
      "Similarity : 0.642, Reviews:평점이 왜케 낮지???? 이영화쩔었는데\n",
      "Similarity : 0.557, Reviews:이런게 헐리우드 작품이라니\n",
      "\n",
      " Original Review 11 : 걍인피니트가짱이다.진짜짱이다♥\n",
      "\n",
      " Top 5 similar reviews using countvectorizer:\n",
      "Similarity : 1.000, Reviews:걍인피니트가짱이다.진짜짱이다♥\n",
      "Similarity : 0.707, Reviews:1,2 편만큼 재미있던데...4부터는 아니지만 3는 진짜 재미있게 봤어요!!\n",
      "Similarity : 0.707, Reviews:우와아아아... 진짜 재미없다\n",
      "Similarity : 0.707, Reviews:진짜 재미있어요.\n",
      "Similarity : 0.707, Reviews:진짜 드럽네\n",
      "\n",
      " Top 5 similar reviews using Tfidf:\n",
      "Similarity : 1.000, Reviews:걍인피니트가짱이다.진짜짱이다♥\n",
      "Similarity : 0.365, Reviews:미쳤음 진짜. 겁나 재밌음.\n",
      "Similarity : 0.365, Reviews:대단하다1시간40분이지루하지않았다와 진짜 ㅋㅋ\n",
      "Similarity : 0.365, Reviews:이것도 진짜 재밌게 본듯\n",
      "Similarity : 0.365, Reviews:왜6점이죠??ㅜㅜ진짜재밌는데\n",
      "\n",
      " Original Review 12 : 볼때마다 눈물나서 죽겠다90년대의 향수자극!!허진호는 감성절제멜로의 달인이다~\n",
      "\n",
      " Top 5 similar reviews using countvectorizer:\n",
      "Similarity : 1.000, Reviews:볼때마다 눈물나서 죽겠다90년대의 향수자극!!허진호는 감성절제멜로의 달인이다~\n",
      "Similarity : 0.354, Reviews:저는 잔잔하고 감성있는게 좋게 봤는데요^^\n",
      "Similarity : 0.250, Reviews:말이 필요없다. 볼때마다 재밌다. 최고.\n",
      "Similarity : 0.250, Reviews:자극적인 장면을 넣는데만 애썼다... 지루하다\n",
      "Similarity : 0.250, Reviews:이거 판타지여 멜로 여?\n",
      "\n",
      " Top 5 similar reviews using Tfidf:\n",
      "Similarity : 1.000, Reviews:볼때마다 눈물나서 죽겠다90년대의 향수자극!!허진호는 감성절제멜로의 달인이다~\n",
      "Similarity : 0.360, Reviews:캬~ 어렸을 적 그 향수. 그립다 그리운 영화\n",
      "Similarity : 0.319, Reviews:마지막 씬에서 향수뿌리는거 빵터짐 ㅋㅋ\n",
      "Similarity : 0.305, Reviews:저는 잔잔하고 감성있는게 좋게 봤는데요^^\n",
      "Similarity : 0.301, Reviews:아무것도 자극적이지 못한 영화\n",
      "\n",
      " Original Review 13 : 울면서 손들고 횡단보도 건널때 뛰쳐나올뻔 이범수 연기 드럽게못해\n",
      "\n",
      " Top 5 similar reviews using countvectorizer:\n",
      "Similarity : 1.000, Reviews:울면서 손들고 횡단보도 건널때 뛰쳐나올뻔 이범수 연기 드럽게못해\n",
      "Similarity : 0.500, Reviews:연기 굿\n",
      "Similarity : 0.500, Reviews:얘네들, 이런거 찍으려고 연기 배운건 아니였을 텐데\n",
      "Similarity : 0.500, Reviews:어색한 연기 어쩔거야..\n",
      "Similarity : 0.500, Reviews:볼만함 약션도좋고 연기도 뛰어나고\n",
      "\n",
      " Top 5 similar reviews using Tfidf:\n",
      "Similarity : 1.000, Reviews:울면서 손들고 횡단보도 건널때 뛰쳐나올뻔 이범수 연기 드럽게못해\n",
      "Similarity : 0.440, Reviews:이범수 너무 멋있어요 !!! 대박\n",
      "Similarity : 0.417, Reviews:잔잔한 감동을 주는 영화. 이은주와 이범수의 좋은 연기^^\n",
      "Similarity : 0.416, Reviews:울면서뛰쳐나간영화는처음ㅜㅜㅜ\n",
      "Similarity : 0.391, Reviews:이 영화보고 안 울면 사람이 아님;;\n",
      "\n",
      " Original Review 14 : 담백하고 깔끔해서 좋다. 신문기사로만 보다 보면 자꾸 잊어버린다. 그들도 사람이었다는 것을.\n",
      "\n",
      " Top 5 similar reviews using countvectorizer:\n",
      "Similarity : 1.000, Reviews:담백하고 깔끔해서 좋다. 신문기사로만 보다 보면 자꾸 잊어버린다. 그들도 사람이었다는 것을.\n",
      "Similarity : 0.577, Reviews:사람들을 보았다.\n",
      "Similarity : 0.577, Reviews:사람을 재우기에 충분했습니다\n",
      "Similarity : 0.577, Reviews:좋은사람밋밋하지않고좋음\n",
      "Similarity : 0.577, Reviews:느그들은 사람 죽이는게 즐겁지?\n",
      "\n",
      " Top 5 similar reviews using Tfidf:\n",
      "Similarity : 1.000, Reviews:담백하고 깔끔해서 좋다. 신문기사로만 보다 보면 자꾸 잊어버린다. 그들도 사람이었다는 것을.\n",
      "Similarity : 0.652, Reviews:cgv에서 자꾸 이거하길래 짜증나서 남김\n",
      "Similarity : 0.570, Reviews:이런거 평점 많이주면 이런거 자꾸 만든다 ..\n",
      "Similarity : 0.503, Reviews:영화가 끝나고도 자꾸 눈물이 쏟아졌다..\n",
      "Similarity : 0.407, Reviews:다니엘헤니 왜자꾸 이런것만 찍는거야??\n",
      "\n",
      " Original Review 15 : 취향은 존중한다지만 진짜 내생에 극장에서 본 영화중 가장 노잼 노감동임 스토리도 어거지고 감동도 어거지\n",
      "\n",
      " Top 5 similar reviews using countvectorizer:\n",
      "Similarity : 1.000, Reviews:취향은 존중한다지만 진짜 내생에 극장에서 본 영화중 가장 노잼 노감동임 스토리도 어거지고 감동도 어거지\n",
      "Similarity : 0.544, Reviews:진짜 감동을 주는 영화 ...\n",
      "Similarity : 0.527, Reviews:엄청난 영화 감동감동.... ㅠㅠ\n",
      "Similarity : 0.500, Reviews:감동적인 영화다\n",
      "Similarity : 0.500, Reviews:너무나 감동적인 영화\n",
      "\n",
      " Top 5 similar reviews using Tfidf:\n",
      "Similarity : 1.000, Reviews:취향은 존중한다지만 진짜 내생에 극장에서 본 영화중 가장 노잼 노감동임 스토리도 어거지고 감동도 어거지\n",
      "Similarity : 0.485, Reviews:개재미없음 막장스토리 어거지 ㅋㅋ\n",
      "Similarity : 0.407, Reviews:어거지도 정도가 있지 제발 그만해\n",
      "Similarity : 0.375, Reviews:내생의 최고의영화 식상하면서도 식상하지않은 이감동\n",
      "Similarity : 0.357, Reviews:극장에서봤어용~잔잔한 감동 좋았습니다....\n",
      "\n",
      " Original Review 16 : ㄱ냥 매번 긴장되고 재밋음ㅠㅠ\n",
      "\n",
      " Top 5 similar reviews using countvectorizer:\n",
      "Similarity : 1.000, Reviews:ㄱ냥 매번 긴장되고 재밋음ㅠㅠ\n",
      "Similarity : 0.577, Reviews:재밋음\n",
      "Similarity : 0.408, Reviews:긴장하고 몰입해서 봤습니다\n",
      "Similarity : 0.408, Reviews:스토리는 뻔하긴했지만 보는내내 지루하지않고 긴장돋앗다\n",
      "Similarity : 0.333, Reviews:긴장되면서 재미있는 이영화 추천드려요.\n",
      "\n",
      " Top 5 similar reviews using Tfidf:\n",
      "Similarity : 1.000, Reviews:ㄱ냥 매번 긴장되고 재밋음ㅠㅠ\n",
      "Similarity : 0.586, Reviews:재밋음\n",
      "Similarity : 0.478, Reviews:스토리는 뻔하긴했지만 보는내내 지루하지않고 긴장돋앗다\n",
      "Similarity : 0.432, Reviews:긴장하고 몰입해서 봤습니다\n",
      "Similarity : 0.400, Reviews:말도안되게 명작 ㅠ 사람들이 죽기전에 꼭봐야할 영화라고 매번 말하는이유를 알겠다 ㅠ\n",
      "\n",
      " Original Review 17 : 참 사람들 웃긴게 바스코가 이기면 락스코라고 까고바비가 이기면 아이돌이라고 깐다.그냥 까고싶어서 안달난것처럼 보인다\n",
      "\n",
      " Top 5 similar reviews using countvectorizer:\n",
      "Similarity : 1.000, Reviews:참 사람들 웃긴게 바스코가 이기면 락스코라고 까고바비가 이기면 아이돌이라고 깐다.그냥 까고싶어서 안달난것처럼 보인다\n",
      "Similarity : 0.426, Reviews:쓰잘데기 없는 기억이기에는 너무 가슴이 아프네요\n",
      "Similarity : 0.426, Reviews:어릴때재밌게봤는데 제목이기억안났던ㅠ 이거였구나ㅠㅜ\n",
      "Similarity : 0.426, Reviews:별덤높이기다디다디도러\n",
      "Similarity : 0.405, Reviews:사람들은 모두 늙어. 왜냐하면 인생이 그런 것이기 때문이지.\n",
      "\n",
      " Top 5 similar reviews using Tfidf:\n",
      "Similarity : 1.000, Reviews:참 사람들 웃긴게 바스코가 이기면 락스코라고 까고바비가 이기면 아이돌이라고 깐다.그냥 까고싶어서 안달난것처럼 보인다\n",
      "Similarity : 0.451, Reviews:쓰잘데기 없는 기억이기에는 너무 가슴이 아프네요\n",
      "Similarity : 0.443, Reviews:어릴때재밌게봤는데 제목이기억안났던ㅠ 이거였구나ㅠㅜ\n",
      "Similarity : 0.379, Reviews:사람들은 모두 늙어. 왜냐하면 인생이 그런 것이기 때문이지.\n",
      "Similarity : 0.368, Reviews:공포도아니고뭔가찝찝한이기분...30분도안되서하나둘씩나간다...나도나왔다...\n",
      "\n",
      " Original Review 18 : 굿바이 레닌 표절인것은 이해하는데 왜 뒤로 갈수록 재미없어지냐\n",
      "\n",
      " Top 5 similar reviews using countvectorizer:\n",
      "Similarity : 1.000, Reviews:굿바이 레닌 표절인것은 이해하는데 왜 뒤로 갈수록 재미없어지냐\n",
      "Similarity : 0.471, Reviews:가면갈수록재미없어짐....\n",
      "Similarity : 0.408, Reviews:잔잔하고 재미도 있어서 좋았다\n",
      "Similarity : 0.408, Reviews:재미만 있구만 뭘 ㅋㅋ\n",
      "Similarity : 0.408, Reviews:잼없다 지루하고 재미가없다 끝\n",
      "\n",
      " Top 5 similar reviews using Tfidf:\n",
      "Similarity : 1.000, Reviews:굿바이 레닌 표절인것은 이해하는데 왜 뒤로 갈수록 재미없어지냐\n",
      "Similarity : 0.414, Reviews:표절?표절?표절?표절\n",
      "Similarity : 0.414, Reviews:표절\n",
      "Similarity : 0.397, Reviews:3시의결투 표절영화\n",
      "Similarity : 0.367, Reviews:이거표절이구만아진짜작작해라\n",
      "\n",
      " Original Review 19 : 이건 정말 깨알 캐스팅과 질퍽하지않은 산뜻한 내용구성이 잘 버무러진 깨알일드!!♥\n",
      "\n",
      " Top 5 similar reviews using countvectorizer:\n",
      "Similarity : 1.000, Reviews:이건 정말 깨알 캐스팅과 질퍽하지않은 산뜻한 내용구성이 잘 버무러진 깨알일드!!♥\n",
      "Similarity : 0.426, Reviews:깨알같은 재미가 있네여~\n",
      "Similarity : 0.369, Reviews:2회 정말재밌었어요 앞으로 더 재밌어진다하니 기대중입니다. 왠지 대박날듯..ㅎㅎ조연들까지 깨알재미주네요\n",
      "Similarity : 0.348, Reviews:와...이건 정말 명작이네요...\n",
      "Similarity : 0.348, Reviews:정말 감동받았어요ㅠㅠㅠ이건 꼭 봐야되요!!!\n",
      "\n",
      " Top 5 similar reviews using Tfidf:\n",
      "Similarity : 1.000, Reviews:이건 정말 깨알 캐스팅과 질퍽하지않은 산뜻한 내용구성이 잘 버무러진 깨알일드!!♥\n",
      "Similarity : 0.552, Reviews:깨알같은 재미가 있네여~\n",
      "Similarity : 0.401, Reviews:촌스럽지도 않고 깨알같은 웃음포인트가 넘치는영화\n",
      "Similarity : 0.332, Reviews:2회 정말재밌었어요 앞으로 더 재밌어진다하니 기대중입니다. 왠지 대박날듯..ㅎㅎ조연들까지 깨알재미주네요\n",
      "Similarity : 0.311, Reviews:인물간의 관계가 살짝 복잡할수도 있음 근데 대사들에 깨알같은 재미가 있다 ㅋㅋㅋ\n",
      "\n",
      " Original Review 20 : 약탈자를 위한 변명, 이라. 저놈들은 착한놈들 절대 아닌걸요.\n",
      "\n",
      " Top 5 similar reviews using countvectorizer:\n",
      "Similarity : 1.000, Reviews:약탈자를 위한 변명, 이라. 저놈들은 착한놈들 절대 아닌걸요.\n",
      "Similarity : 0.577, Reviews:이게 10점이라고? 절대보지마라\n",
      "Similarity : 0.577, Reviews:절대적으로 나쁘게 봤음...ㅠㅠ\n",
      "Similarity : 0.577, Reviews:절대비추.....\n",
      "Similarity : 0.480, Reviews:정승필 이후에 이감독 영화 절대절대절대 안봄\n",
      "\n",
      " Top 5 similar reviews using Tfidf:\n",
      "Similarity : 1.000, Reviews:약탈자를 위한 변명, 이라. 저놈들은 착한놈들 절대 아닌걸요.\n",
      "Similarity : 0.418, Reviews:절대비추.....\n",
      "Similarity : 0.418, Reviews:절대적으로 나쁘게 봤음...ㅠㅠ\n",
      "Similarity : 0.418, Reviews:이게 10점이라고? 절대보지마라\n",
      "Similarity : 0.344, Reviews:정승필 이후에 이감독 영화 절대절대절대 안봄\n"
     ]
    }
   ],
   "source": [
    "# 코사인 유사도를 통해 리뷰 20개 정도 추려서\n",
    "# 리뷰와 코사인유사도가 같은 5개 정도를 출력하는 코드\n",
    "\n",
    "num_rvs = 20\n",
    "for i in range(num_rvs):\n",
    "    # cv\n",
    "    simliar_indices_count = cos_sim_count[i].argsort()[::-1][0:5]\n",
    "    simliar_reviews_count = [(cos_sim_count[i][j], df_sp['document'][j]) for j in simliar_indices_count]\n",
    "    \n",
    "    # tfidf\n",
    "    simliar_indices_tfidf = cos_sim_tfidf[i].argsort()[::-1][0:5]\n",
    "    simliar_reviews_tfidf = [(cos_sim_tfidf[i][j], df_sp['document'][j]) for j in simliar_indices_tfidf]\n",
    "    \n",
    "    print(f\"\\n Original Review {i+1} : {df_sp['document'][i]}\")\n",
    "    print(\"\\n Top 5 similar reviews using countvectorizer:\")\n",
    "    for sim_score, reviews in simliar_reviews_count:\n",
    "        print(f\"Similarity : {sim_score:.3f}, Reviews:{reviews}\")\n",
    "    \n",
    "    print(\"\\n Top 5 similar reviews using Tfidf:\")    \n",
    "    for sim_score, reviews in simliar_reviews_tfidf:\n",
    "        print(f\"Similarity : {sim_score:.3f}, Reviews:{reviews}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LDA  \n",
    "- 토픽 모델링  \n",
    "- 텍스트 기반 문서에서 핵심 주제(Topic)을 찾는다. 데이터 분석 방법론  \n",
    "- 작동방법  \n",
    "    - 확률 기반으로 텍스트의 문서 내에 토픽들이 어떤 비율로 구성되어 있는지 확인  \n",
    "    - 임의 토픽을 분석가가 정한 다음에, 해당 토픽에 대해서 카운팅을 해보고 ( 임의로 카운팅 )  \n",
    "    - 다른 리뷰들이 어떤 식으로 토픽이 분포되어 있는지 보고 맞춰가면서 새로운 리뷰 단어에 대해서 토픽을 찾는다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LatentDirichletAllocation(n_components=2, random_state=111)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LatentDirichletAllocation</label><div class=\"sk-toggleable__content\"><pre>LatentDirichletAllocation(n_components=2, random_state=111)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LatentDirichletAllocation(n_components=2, random_state=111)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 사이킷런에서 제공하는 패키지\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# LDA 모델 생성\n",
    "# 내가 원하는 토픽 주제는 분석가가 정할 수 있다. 2개, 3개\n",
    "# 2개의 토픽을 정하는데, 이 토픽은 어떤 특정 값이 아니라 계산해서 유사하다고 판단되는 토픽들을 묶어서 보여주는 것\n",
    "# 해석의 의미는 분석가가 진행해야 한다.\n",
    "lda = LatentDirichletAllocation(n_components = 2, random_state=111)\n",
    "\n",
    "lda.fit(X_cv_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0\n",
      "영화 진짜 평점 연기 최고 스토리 생각 보고 배우 재미\n",
      "Topic #1\n",
      "정말 사람 내용 영화 드라마 사랑 이야기 이영화 그냥 장면\n"
     ]
    }
   ],
   "source": [
    "# lda에 있는 값들을 출력해야 한다.\n",
    "# 상위 몇 개 단어를 가지고 올 것인가?\n",
    "n_top_words = 10\n",
    "\n",
    "def print_top_words(model, feature_name, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(f\"Topic #{topic_idx}\")\n",
    "        print(\" \".join([feature_name[i] for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "\n",
    "tf_feature_names = cv.get_feature_names_out()\n",
    "print_top_words(lda, tf_feature_names, n_top_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
